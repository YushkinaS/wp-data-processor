Мне понравилась идея https://github.com/systemo-biz/bulk-post-updater. В двух словах, что там: длительная обработка множества записей делится на части. Отработав, функция обработки вызывает себя заново через ajax. Плюс можно следить за ходом процесса через heartbeat api. Я переделала этот код в что-то вроде фреймворка, который организует выполнение кода, упакованного в класс по определенным правилам:

- Класс должен иметь метод start(), возвращающий название первого метода, который нужно выполнить.
```
	function start() {
		return 'parse_file';
	}
 ```
 
- Все методы, которые будут выполняться через data-processor, должны возвращать название следующего метода. Можно организовать ветвления и иклы (получается подобие конечного автомата). Если следующего метода нет (работа закончена) - нужно вернуть 'finish'.
- Все промежуточные результаты нужно писать в БД (set_transient()) - каждый вызов пересоздает классы, и переменных, созданных в прошлый раз, мы уже не увидим.

Класс data-processor нужно подключить к своему плагину.
```
require_once('data-processor.php');
```
И при создании экземпляра параметром указать экземпляр собственного класса.
```
$my_class_instance = new MyClass();
$data_processor = new DataProcessor($my_class_instance);
```

Пример - простенький парсер данных. Можно взять любой csv файл, например этот: 
http://data.gov.ru/opendata/7451208572-reestlic/data-20160525T0515-structure-20160525T0515.csv?encoding=UTF-8
Назвать его data.csv и положить в папку плагина.

Мой плагин будет парсить этот файл и создавать записи, слаги и названия которых возьмет из 0 и 1 колонок файла. Все просто, но записей будет около 8 тысяч.

parse_file() - разобьет файл на строчки и поместит их в транзиенты.
parse_entry() - будет перебирать эти транзиенты, создавать запись и удалять транзиент. Когда работа будет окончена - вернет 'finish'
